#!/usr/bin/env python

"""
Rudder test framework

Usage:
    rtf platform list
    rtf platform status <platform>
    rtf platform setup <platform> [<key>=<value> ...] [<version>]
    rtf platform destroy <platform>
    rtf platform share <platform>
    rtf platform export <platform> [--ova]
    rtf platform shutdown <platform>
    rtf platform snapshot <platform>
    rtf platform rollback <platform>
    rtf platform update-rudder <platform> <version>
    rtf platform update-os <platform> <version>
    rtf host list <platform>
    rtf host update-rudder <host> <version>
    rtf host update-os <host> <version>
    rtf scenario list
    rtf scenario doc <scenario>
    rtf scenario env <platform>
    rtf scenario ncf_tests <platform> <version> [--cfengine-version=<cfengine_version>]
    rtf scenario run <platform> <scenario> [--no-finally] [--stop] [--filter=<test1>,<test2>,...] [--format=<format>] [<KEY>=<VALUE>]... [--destroy-on-error]
    rtf scenario technique <platform> <directory> [--technique=<pattern>] [--last-version] [--no-finally] [--stop] [--filter=<test1>,<test2>,...] [--format=<format>] [--start=<test number>] [--destroy-on-error]
    rtf test from-rule <platform> <uuid> <test_name> [--create-scenario]
    rtf test from-directive <platform> <uuid> <test_name> <path>

Options:
    --ova                  Export in ova format (the platform status is not kept)
    --no-finally           Do not run tests tagged FINALLY in the scenario, to avoid coming back to initial state
    --stop                 Stop test on first error
    --filter=...           Only run provided test list from scenario
    --format=<format>      Output format to use (progress, documentation, html or json) [Default: documentation]
    --create-scenario      Generate a sample scenario file to use this test independantly
    --technique=...        Run the technique scenario on the given technique (instead of all technique found)
    --start=<test number>  Run and start the scenario from a given test.
    --cfengine-version=... Define the version of cfengine used to execute the ncf_tests, like 3.10 3.12 rudder-4.3 rudder-latest or ci/rudder-3.2.1
    --destroy-on-error     Destroy the platform if an error is encountered in the run process (scenarii only)

Commands
    All *platform* command are related to platform management. A platform is described is the platforms directory and
    consists of one or more VM in the same network with zero or one rudder component installed.

    All *host* commands are related to a single host within a given platform.

    All *scenario* commands are related to test scenarii. A scenario consists of many successive call to single tests and
    is described in the scenario directory.

    All *test* commands are related to single tests. A test is a serverspec file that calls a command an tests its
    outcome. A test can be used in many different scenarii.

    rtf platform list
        List all available platforms.

    rtf platform status <platform>
        Display current status of given platform.

    rtf platform setup <platform> [<key>=<value> ...] [<version>]
        Create and run the given platform's VMs if they are not already up and running.
        Any value from the platform file can be overrided using a key=value parameter.
        The installed Rudder version can be overrider using a single version parameter.

    rtf platform destroy <platform>
        Destroy all VMs in a given platform.

    rtf platform share <platform>
        Share the platform using Hashicorp's atlas. You need an atlas account to do this.

    rtf platform export <platform> [--ova]
        Export the platform in tgz or on ova.

        The tgz form contrains a script to prepare and run th platform on a new machine.
        It must be used on linux with vagrant and on the same major version of virtualbox.

        The ova form export independant VMs archives that can be (theoretically) used on
        any virtualization product. Be careful, this form destroys the original platform.

    rtf platform shutdown <platform>
        Shutdown all VMs without destroying them.

    rtf platform snapshot <platform>
        Snapshots all VMs.

    rtf platform rollback <platform>
        Rollback all VMs to teh last snapshot (in the right order to keep Rudder working).

    rtf platform update-rudder <platform> <version>
        Upgrade Rudder on all machines of the platform.

    rtf platform update-os <platform> <version>
        Upgrade the OS on all machines of the platform.

    rtf host list <platform>
        List hosts of the platform.

    rtf host update-rudder <host> <version>
        Upgrade Rudder on a single host of the platform.

    rtf host update-os <host> <version>
        Upgrade the OS on a single host of the platform.

    rtf scenario list
        List all available scenarii.

    rtf scenario doc <scenario>
        Print documentation of the scenario.

    rtf scenario env <platform>
        Output environment variables used to run a scenario on the platform.
        Useful to run tests by yourself.

    rtf scenario ncf_tests <platform> <version>
        Setup the given platform, install ncf from git in the specified version and then run the ncf tests.
        When no cfengine version is specified, tests will be executed with the cfengine agent shipped with the
        Rudder agent in the same version than the ncf version specified.

    rtf scenario run <platform> <scenario> [--no-finally] [--stop] [--filter=<test1>,<test2>,...] [--format=<format>] [<KEY>=<VALUE>]...
        Run a single scenario on a given platform.
        Scenario specific parameters must be provided using additional KEY=VALUE.
        See *Options* for more options.

    rtf scenario technique <platform> <directory> [--technique=<pattern>] [--last-version] [--no-finally] [--stop] [--filter=<test1>,<test2>,...] [--format=<format>]
        Push a list of techniques to the platform's server and run matching tests using the "technique" scenario.
        Techniques are all the one found under the <directory>
        Use --last-version when you want to use only test last technique version (directory must be a subdirectory of rudder-techniques)
        Use --technique to provide a pattern (woldcard based) to filter the list of technique to test (ex: rpmPackageInstallation/5.1)

    rtf test from-rule <platform> <uuid> <test_name> [--create-scenario]
        Generate a test from an existing rule on the platform.
        This create files to recreate the directive and the rules on all hosts.
        The test file also contains a stub test to check that everything has worked.

    rtf test from-directive <platform> <uuid> <test_name> <path>
        Generate a technique test from an existing directive on the platform.
        This create files to recreate the directive data, a metadata file and a stub test
        in the destination path.

"""

from __future__ import print_function
from subprocess import Popen, PIPE
import json
import random
import time
import os
import shutil
import copy
import re
import sys
import importlib
import signal
import socket
import pexpect
import requests
import docopt
import scenario.lib
# Hack to import rudder lib, remove, some day ...
sys.path.insert(0, "./rudder-api-client/lib.python")
from rudder import RudderEndPoint, RudderError

# Run a command in a shell like a script would do
# And inform the user of its execution
def shell(command, fail_exit=True, keep_output=True, live_output=False):
  if keep_output:
    if live_output:
      process = Popen(command, shell=True, universal_newlines=True)
    else:
      process = Popen(command, stdout=PIPE, shell=True, universal_newlines=True)
    output, error = process.communicate()
    retcode = process.poll()
  else: # keep tty management and thus colors
    process = Popen(command, shell=True)
    retcode = process.wait()
    output = None
  if fail_exit and retcode != 0:
    print(command)
    print("*** COMMAND ERROR " + str(retcode))
    exit(1)
  return (retcode, output)

class Host:
  """Generic Host
  Inherit to create host managed by a specific provider
  Look at Vagrant class for the list of methods to implement
  """
  def __init__(self, host_info):
    self.info = host_info

use_proxy = ''
def have_proxy():
  global use_proxy
  nrm_proxy = "http://filer.interne.normation.com:3128"
  proxy_line = "http_proxy="+nrm_proxy+" https_proxy="+nrm_proxy+" HTTP_PROXY="+nrm_proxy+" HTTPS_PROXY="+nrm_proxy+" "
  if use_proxy is not '':
    return use_proxy
  socket.gethostbyname(socket.gethostname())
  s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
  s.connect(("8.8.8.8", 80))
  if s.getsockname()[0].startswith('192.168.90.'):
    nrm_ip = socket.gethostbyname("republique-1.normation.com.")
    req = requests.get("http://ipinfo.io/ip")
    if req.status_code == 200:
      if req.content.strip() == nrm_ip:
        use_proxy = proxy_line
  return use_proxy

### Vagrant specific code ###

def host_lines(platform, hosts, pf_id):
  """ Return a Vagrantfile host line """
  pf = platform.split('.')[0]
  lines = []
  i = 1
  host_list = sorted(hosts.keys(), reverse=True)
  hostnames = " ".join(host_list)

  # detect the need for windows support
  windows_support = False
  dsc_support = False
  for hostname in host_list:
    # add pf_id to the host object
    hosts[hostname].info['pf_id'] = str(pf_id)
    if hosts[hostname].info['provider'] == 'aws':
      command = "configure_aws"
    else:
      command = "configure"
    if hosts[hostname].info['system'].startswith("win"):
      if hosts[hostname].info['rudder-setup'] == "rudder-agent-cfengine":
        windows_support = True
      else:
        dsc_support = True

  # detect default server node
  server = ""
  for hostname in host_list:
    if 'server' in hosts[hostname].info['rudder-setup']:
      server = hostname

  # write a line for each host
  for hostname in host_list:
    host = hosts[hostname].info
    if host['run-with'] == 'vagrant':
      os = host['system']
      if  host['provider'] == 'aws':
        os = "aws_" + os

      if 'server' in host['rudder-setup']:
        host_id = "0"
      else:
        host_id = str(i)
        i += 1

      # Define server the node is pointing to
      own_server = ""
      if 'server' in host:
        own_server = host['server']
      elif host['rudder-setup'] != 'server':
        own_server = server

      # generic host
      line = command + "(config, $" + os + ", '" + pf + "', " + str(pf_id) + ", '" + hostname +"', " + host_id
      line += ", setup:'" + host['rudder-setup']  + "', host_list:'" + hostnames + "'"
      # rudder host
      if host['rudder-setup'] != 'ncf' and host['rudder-setup'] != 'empty':
        line += ", version:'" +  host['rudder-version'] + "', server:'" + own_server + "'"
      # ncf host
      if host['rudder-setup'] == 'ncf':
        line += ", ncf_version:'" + host['ncf-version'] + "', cfengine_version:'" +  host['cfengine-version'] + "'"

      # windows support
      if 'server' in host['rudder-setup'] and windows_support:
        line += ", windows_plugin:true"
      if 'server' in host['rudder-setup'] and dsc_support:
        line += ", dsc_plugin:true"
      # ram param
      if 'ram' in host:
        line += ", ram:"+ str(host['ram'])
      # External provisionning
      if 'provision' in host:
        line += ", provision:false"
      line += ")\n"
      lines.append(line)
  return lines

def init_vagrantfile():
  """ Initialize an empty Vagrantfile """
  if os.path.isfile("Vagrantfile"):
    return
  with open("Vagrantfile", "w") as vagrant:
    vagrant.write("""# -*- mode: ruby -*-
# vi: set ft=ruby :

require_relative 'vagrant.rb'

Vagrant.configure("2") do |config|
config.vm.provider 'virtualbox' do |v|
    v.linked_clone = true if Vagrant::VERSION =~ /^1.8/
end
if Vagrant.has_plugin?("vagrant-cachier")
  config.cache.scope = :box
end

if Vagrant.has_plugin?("vagrant-aws")
  #$AWS_KEY='xxxxxxxxxxxxxxxxxxxx'
  #$AWS_SECRET='xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'
  
  # name of your key (region specific)
  #$AWS_KEYNAME='my_keyPair'
  # vpc id
  #$AWS_VPC='subnet-xxxxxxxx'
  # vpc security groups id, do not use the group name
  #$AWS_SERVER_GROUP='sg-xxxxxxxx'
  #$AWS_RELAY_GROUP='sg-xxxxxxxx'
  #$AWS_AGENT_GROUP='sg-xxxxxxxx'
  
end
### AUTOGEN TAG

end
""")


class Vagrant(Host):
  """ Vagrant managed host """
  def __init__(self, platform, name, host_info):
    Host.__init__(self, host_info)
    pf = platform.split('.')[0]
    self.platform = pf
    self.name = name
    self.hostid = pf + '_' + name
    self.provider = host_info["provider"]
    self.commands = {}
    init_vagrantfile()

  def start(self):
    """ Setup and run this host """
    proxy = have_proxy()
    while "making sure that no vagrant up are running":
      (returncode, output) = shell("pgrep -f \"[v]agrant up\"", fail_exit=False)
      if returncode != 1:
        idle = random.randint(5, 10)
        print("Another vagrant session is currently running, waiting " + str(idle) + " seconds")
        time.sleep(idle)
      else:
        break
    os.system(proxy + "vagrant up " + self.hostid + " --provider="+self.provider)

  def stop(self):
    """ Destroy this host """
    os.system("vagrant destroy -f " + self.hostid)

  def export(self, directory):
    """ Export this VM using Virtualbox commads """
    fullname = os.path.basename(os.getcwd()).replace('.', '') + '_' + self.hostid
    # List VMs and do something on the one we are working on
    for line in os.popen("VBoxManage list vms"):
      m = re.match(r'"' + fullname + r'[0-9_]+" \{(.*)\}', line)
      if m:
        uuid = m.group(1)
        running = False
        print("Exporting " + fullname + " / " + uuid + " to directory " + directory)
        # If the VM is running, pause it (and save its state) and rerun it later
        for running_line in os.popen("VBoxManage list runningvms"):
          if re.search(uuid, running_line):
            running = True
        if running:
          os.system("VBoxManage controlvm " + uuid + " savestate")
        os.system("VBoxManage clonevm " + uuid + " --options keepallmacs --options keepdisknames --name " + self.hostid + " --basefolder " + directory)
        disk_uuid = ""
        # work around a virtualbox bug, when you clone a vm, the new disk is registered, whateverthe parameters -> unregister it
        for disk_line in os.popen("VBoxManage list hdds"):
          m = re.match(r'UUID:\s+([0-9a-f\-]+)', disk_line)
          if m:
            disk_uuid = m.group(1)
          if re.match(r'Location:\s+'+directory+'/'+self.hostid, disk_line):
            os.system("VBoxManage closemedium disk " + disk_uuid)
        if running:
          os.system("VBoxManage startvm " + uuid + " --type headless")

  def ssh_config(self, key_directory):
    """ get ssh configuration to connect to this machine """
    (code, output) = shell("vagrant ssh-config " + self.hostid, fail_exit=False)
    if code != 0:
      print("Cannot get ssh-configuration for " + self.hostid)
      print("A patch for vagrant is available here https://github.com/peckpeck/vagrant/commit/93c5b853511548087fba7e8813c34ee45226e1cc")
      print("Halting!")
      exit(14)
    m = re.search(r'\sIdentityFile\s+(\S+)', output)
    if m:
      src = m.group(1)
      output = re.sub(r'(\sIdentityFile)\s+\S+', r'\1 '+os.path.basename(key_directory)+'/'+self.hostid, output)
      shutil.copy(src, key_directory+'/'+self.hostid)
    return output

  def halt(self):
    """ Halt this host """
    os.system("vagrant halt " + self.hostid)

  def snapshot(self):
    """ Snapshot this host """
    os.system("vagrant snapshot push " + self.hostid)

  def rollback(self):
    """ Go to last snapshot on this host """
    os.system("vagrant snapshot pop " + self.hostid)

  def run(self, command, fail_exit=True, live_output=False):
    """ Run a command as root on this host """
    (code, value) = shell("vagrant ssh " + self.hostid + " -c \"sudo /bin/sh -c 'PATH=\\$PATH:/vagrant/scripts LANG=C " + command + "'\" -- -q", fail_exit=fail_exit, live_output=live_output)
    if not live_output:
      token = re.sub('==>.*\n', '', value)
      return token.rstrip()

  def cached_run(self, command, fail_exit=True):
    if command in self.commands:
      return self.commands[command]
    value = self.run(command, fail_exit)
    self.commands[command] = value
    return value

  def push(self, source, destination):
    os.system("vagrant scp \"" + source + "\" \"" + self.hostid + ":" + destination + "\"")

  def pull(self, source, destination):
    os.system("vagrant scp \"" + self.hostid + ":" + source + "\" \"" + destination + "\"")

  def push_techniques(self, directory):
    """ Replace all techniques with the provided ones """
    # First, erase technique directories matching the tested one
    name = os.path.basename(os.path.abspath(directory))
    self.run("cd /var/rudder/configuration-repository/techniques/ && find -mindepth 1 -type d -name " + name + " | xargs rm -rf ", fail_exit=False)
    # Then push new techniques
    self.push(directory, "/tmp/")
    self.run("mv /tmp/" + name + " /var/rudder/configuration-repository/techniques/")
    self.run("cd /var/rudder/configuration-repository/techniques/ && git add --all . && git commit --allow-empty -m 'Replacing all techniques with the test ones' && rudder server reload-techniques")

  def share(self, password):
    """ Shares this box via vagrant cloud """
    # make sure the VM is running
    os.system("vagrant up " + self.hostid)
    # run vagrant share, provide a password, print its output and extract the command to run
    process = pexpect.spawn("/usr/bin/vagrant share --disable-http --ssh "+ self.hostid)
    process.expect("Please enter a password to encrypt the key: ")
    print(process.before, end='')
    process.sendline(password)
    process.expect("Repeat the password to confirm: ")
    print(process.before, end='')
    process.sendline(password)
    process.expect(r'==> \w+: simply has to run `(vagrant connect --ssh .*?)`')
    command = process.match.group(1)
    print(process.before, end='')
    process.expect(r'in some secure way..*')
    print(process.before, end='')
    print(process.after, end='')
    return (self.hostid, command, process)

  def get_url(self):
    """ Get matching server URL """
    # port autodetection
    port = None
    for line in open("Vagrantfile"):
      # match configure(config, pf_name, 'platform', id, 0, 'version')
      m = re.match(r'configure\((?:.*?,){2}\s*' + "'" + self.platform + "'" + r'\s*,\s*(\d+)', line)
      if m:
        port = str(int(m.group(1)) * 100 + 8081)
        break
      #Test if it is an AWS instance
      else:
        aws = re.match(r"configure_aws\(.+" + self.platform + "', [0-9]+, '(\S+)'.+", line)
        if aws:
          command = "vagrant ssh-config " + self.platform + "_" + aws.group(1)
          (code, output) = shell(command)
          adress = re.match(r'[\s\S]+HostName (.*)', output)
          return "https://" + adress.group(1) + "/rudder"
    if port is None:
      return None
    return "https://localhost:" + str(port) + "/rudder"

  @staticmethod
  def status(platform, hosts):
    """ Return the status of all hosts on a given platform """
    host_list = [platform + '_' + h for h in hosts]
    os.system("vagrant status " + " ".join(host_list))

  @staticmethod
  def reset_platform(name, hosts):
    """ Update or replace the Vagrantfile configuration for the given platform """
    lines = []
    # parse Vagrantfile into the lines array (and update it)
    with open("Vagrantfile", "r+") as fd:
      updated = False
      line = fd.readline()
      max_pf_id = 0
      min_pf_id = 256
      ids = []
      header_re = re.compile(r'### AUTOGENERATED FOR PLATFORM (\w+) \((\d+)\)')
      while line:
        # find max platform id so that we can add a new one if needed
        m = header_re.match(line)
        if m:
          pf_id = int(m.group(2))
          ids.append(pf_id)
          if pf_id > max_pf_id:
            max_pf_id = pf_id
          if pf_id < min_pf_id:
            min_pf_id = pf_id
        # look for the platform we want to modify and update its content
        if not updated and m and m.group(1) == name:
          lines.append(line) # re-add the header
          pf_id = int(m.group(2))
          while not re.match(r'### END OF AUTOGENERATION FOR ' + name, line):
            line = fd.readline()
          lines.extend(host_lines(name, hosts, pf_id))
          lines.append(line) # re-add the footer
          updated = True
        # no existing platform, create a new one
        elif not updated and re.match(r'### AUTOGEN TAG', line):
          # Look for next id, default case would be to get max+1
          next_id = max_pf_id + 1
          # But we prefer to use min - 1
          if min_pf_id > next_id:
            min_pf_id = next_id
          if min_pf_id > 1:
            next_id = min_pf_id - 1
          else:
            # If min = 1, tries to find and id between two used ids
            for x in range(1, max_pf_id):
              if not x in ids:
                next_id = x
                break
          if next_id >= 256:
            print(" New platform id will be "+next_id+" which will fail (invalid ip, ...) , please delete some platform before creating a new one")
            exit(6)
          lines.append('### AUTOGENERATED FOR PLATFORM ' + name + " (" + str(next_id) + ") https://localhost:" + str(80+next_id) + "81/ \n")
          lines.extend(host_lines(name, hosts, next_id))
          lines.append('### END OF AUTOGENERATION FOR ' + name + "\n")
          lines.append("\n### AUTOGEN TAG\n")
          updated = True
        # unknown line, keep it
        else:
          lines.append(line)
        line = fd.readline()
      # rewrite the file
      fd.seek(0)
      fd.truncate()
      fd.writelines(lines)

  @staticmethod
  def remove_platform(name):
    """ Update or replace the Vagrantfile configuration by removing the given platform """
    lines = []
    # parse Vagrantfile into the lines array (and update it)
    with open("Vagrantfile", "r+") as fd:
      updated = False
      line = fd.readline()
      max_pf_id = 0
      matched = False
      while line:
        if re.match(r'### AUTOGENERATED FOR PLATFORM ' + name, line):
          matched = True
        if not matched:
          lines.append(line)
        if re.match(r'### END OF AUTOGENERATION FOR ' + name, line):
          matched = False
        line = fd.readline()
      # rewrite the file
      fd.seek(0)
      fd.truncate()
      fd.writelines(lines)

### End of vagrant specific code ###
# Global list of host type
host_types = {'vagrant': Vagrant}

class Platform:
  """ A test platform
  Can be setup or teared down at once
  Can be used to run a test scenario
  """
  def __init__(self, name, platform_info, override):
    self.name = name
    self.hosts = {}
    self.provider = "virtualbox"
    # manage default values
    default = platform_info['default']
    for hostname, host in platform_info.items():
      if hostname == "default":
        continue
      host_info = copy.deepcopy(default)
      if not "provider" in host_info:
        host_info["provider"] = self.provider
      else:
        self.provider = host_info["provider"]
      host_info.update(host)
      host_info.update(override)
      class_name = host_info['run-with']
      # New host object (Vagrant/AWS/...)
      self.hosts[hostname] = host_types[class_name](name, hostname, host_info)

  def setup(self, client_path):
    """ Startup the full platform """
    for host_type in host_types.values():
      host_type.reset_platform(self.name, self.hosts)
    for hostname in sorted(self.hosts.keys(), reverse=True):
      self.hosts[hostname].start()

    for hostname in sorted(self.hosts.keys(), reverse=True):
      host = self.hosts[hostname]
      if ('provision' in host.info and 'python' in host.info['provision']):
        unsupported = os.getenv('UNSUPPORTED', "")
        repoPrefix = "rtf/"
        rudderSetup = host.info['rudder-setup']
        rudderVersion = host.info['rudder-version']
        proxy = have_proxy()

        # guessing the authorized network
        baseNetwork = 40
        with open("Vagrantfile", "r+") as fd:
          line = fd.readline()
          reg = re.compile("\$NET_PREFIX=(\d+).*")
          while line:
            m = reg.match(line)
            if m:
                baseNetwork = int(m.group(1))
                break
            line = fd.readline()
        try:
          server = host.info['server']
        except:
          server = ""

        allowedNetwork = "192.168." + str(int(host.info['pf_id']) + baseNetwork) + ".0"

        host.run("sed -i s/set\ -e/set\ -xe/g /usr/local/bin/rudder-setup")
        host.run("%s ALLOWEDNETWORK=%s/24 UNSUPPORTED=%s REPO_PREFIX=%s ; /usr/local/bin/rudder-setup setup-%s \"%s\" \"%s\"" %(proxy, allowedNetwork, unsupported, repoPrefix, rudderSetup, rudderVersion, server), live_output=True)
        if 'server' in host.info['rudder-setup']:
          host.run("/vagrant/scripts/create-token")
    relay_list = []
    # Find all relays uuid
    for host in self.hosts.values():
      if 'relay' in host.info['rudder-setup']:
        uuid = host.run("cat /opt/rudder/etc/uuid.hive")
        relay_list.append(uuid)

    # Promote relays on servers
    if relay_list:
      for host in self.hosts.values():
        if 'server' in host.info['rudder-setup']:
          # Treat inventory received on the server
          print(host.run("/opt/rudder/bin/rudder agent run"))
          # Environment setup
          rudder_url = host.get_url()
          token = host.run('cat /root/rudder-token')
          setenv(client_path, rudder_url, token)
          for relay in relay_list:
            # Accept the relay
            rcli = "rudder-cli --skip-verify --url=" + rudder_url + " --token=" + token
            command = rcli + " nodes accept "+ relay
            (code, output) = shell(command)
            print(output)
            # Promote to relay
            print(host.run("/opt/rudder/bin/rudder-node-to-relay "+relay))
            print(host.run("curl https://localhost/rudder/api/deploy/reload -k"))

  def export(self):
    """ Export the full platform in a tgz """
    # This is virtualbox/vagrant specific and should be refactored when we add a new provider
    dirname = os.getcwd() + "/rtf-" + self.name
    if not os.path.exists(dirname):
      os.mkdir(dirname)

    # create ssh configuration early since it can fail (fail early)
    keydir = dirname + "/keys"
    if not os.path.exists(keydir):
      os.mkdir(keydir)
    with open(dirname+'/ssh_config', 'w') as outfile:
      for host in self.hosts.values():
        outfile.write(host.ssh_config(keydir))

    # create vm dumps
    for host in self.hosts.values():
      host.export(dirname)

    print("Creating package")
    # create startup script
    with open(dirname+'/run', 'w') as outfile:
      outfile.write("#!/bin/sh\n")
      for host in self.hosts.values():
        outfile.write("VBoxManage registervm $(pwd)/" + host.hostid + "/" + host.hostid + ".vbox\n")
        outfile.write('UUID=$(VBoxManage list vms | grep "\\"' + host.hostid + '\\"" | ' + "perl -pe 's/.*\{(.*)\}.*/$1/')\n")
        outfile.write("VBoxManage startvm $UUID --type headless\n")
      outfile.write("echo ''\n")
      outfile.write("echo 'You can now connect to VMs using ssh -F ssh_config <vmname>'\n")
      outfile.write("echo 'Available VMs are: '\n")
      for host in self.hosts.values():
        outfile.write("echo '"+host.hostid+"'\n")
      outfile.write("echo ''\n")
    os.chmod(dirname+'/run', 0o755)
    # create shutdown script
    with open(dirname+'/terminate', 'w') as outfile:
      outfile.write("#!/bin/sh\n")
      for host in self.hosts.values():
        outfile.write('UUID=$(VBoxManage list vms | grep "\\"' + host.hostid + '\\"" | ' + "perl -pe 's/.*\{(.*)\}.*/$1/')\n")
        outfile.write("[ -n \"$UUID\" ] && VBoxManage controlvm $UUID poweroff\n")
        outfile.write("[ -n \"$UUID\" ] && VBoxManage unregistervm $UUID\n")
      outfile.write("echo 'You can now safely remove this directory!'\n")
    os.chmod(dirname+'/terminate', 0o755)

    # Create tgz
    os.system("tar czf rtf-" + self.name + ".tgz " + os.path.basename(dirname))
    shutil.rmtree(dirname)

  def export_ova(self):
    """ Export each machines in the platform as a separate ova """
    # This is virtualbox/vagrant specific and should be refactored when we add a new provider
    dirname = os.getcwd() + "/vms-" + self.name
    if not os.path.exists(dirname):
      os.mkdir(dirname)

    for host in self.hosts.values():
      # no selinux to avoid nasty bugs
      #host.run("sed -i 's/SELINUX=.*/SELINUX=disabled/' /etc/selinux/config || true")
      # reconfigure network ?
      # stop
      host.halt()

    i = 0
    for host in self.hosts.values():
      uuid = os.popen("VBoxManage list vms | grep '" + host.hostid + "' | perl -pe 's/.*\{(.*)\}.*/$1/'").read().strip()
      host.uuid = uuid

      # configure host network ?

      for line in os.popen("VBoxManage showvminfo " + uuid + " --machinereadable"):
        # remove vagrant share
        match = re.match(r'SharedFolderName.*="(.*)"', line)
        if match:
          os.system("VBoxManage sharedfolder remove " + uuid + " --name " + match.group(1))
        # remove redirects
        match = re.match(r'Forwarding.*="(.*?),.*"', line)
        if match:
          os.system("VBoxManage modifyvm " + uuid + " --natpf1 delete " + match.group(1))
      # reconfigure redirects
      port = 2022+i
      i += 1
      os.system("VBoxManage modifyvm " + uuid + " --natpf1 \"ssh,tcp,127.0.0.1," + str(port) + ",,22\"")
      if host.info['rudder-setup'] == 'server':
        os.system("VBoxManage modifyvm " + uuid + " --natpf1 \"tcp80,tcp,,8080,,80\"")
        os.system("VBoxManage modifyvm " + uuid + " --natpf1 \"tcp443,tcp,,8081,,443\"")

      # add video memory and rename
      os.system("VBoxManage modifyvm " + uuid + " --name " + host.name + " --vram 32")

      # export
      os.system("VBoxManage export " + uuid + " -o " + dirname + "/" + host.name + ".ova --ovf09 --manifest")

    # cleanup, those VMs are not suitable anymore for rtf
    # Just comment since the user may want to do things again and reexport
    print("The platform " + self.name + " is not suitable for use with rtf anymore.")
    print("Please destroy the VMs when you don't need them anymore, either with virtualbox interface or via those commands:")
    for host in self.hosts.values():
      print("VBoxManage unregistervm " + host.uuid + " --delete")

  def shutdown(self):
    """ Stop the full platform """
    for host in self.hosts.values():
      host.halt()

  def snapshot(self):
    """ Snapshot the full platform """
    for host in self.hosts.values():
      host.snapshot()

  def rollback(self):
    """ Snapshot the full platform """
    for host in self.hosts.values():
      host.rollback()

  def teardown(self):
    """ Stop and destroy the full platform """
    for host in self.hosts.values():
      host.stop()
    # remove it from vagrant
    for host_type in host_types.values():
      host_type.remove_platform(self.name)

  def push_techniques(self, directory):
    for host in self.hosts.values():
      if host.info['rudder-setup'] == 'server':
        host.push_techniques(directory)

  def share(self):
    """ Share the platform via vagrant cloud """
    # Some of this is vagrant specific, it should be refactored when we add a new provider
    password = "password" # this can be a security risk, but:
                          #    it's only test machines
                          #    you need to know they are running
                          #    you need to know their share ID
    # Check that the user is logged in
    code = os.system("vagrant login -c")
    if code != 0:
      print("You need an atlas hashicorp login to use this feature.")
      print("Go to https://atlas.hashicorp.com/ to create one.")
      print("")
      print("If you already have an account, type 'vagrant login' and then re-run this command.")
      exit(4)
    signal.signal(signal.SIGINT, empty_handler)
    signal.signal(signal.SIGTERM, empty_handler)
    # share
    shared_process = []
    for host in self.hosts.values():
      shared_process.append(host.share(password))
    # display info
    print("")
    print("Now you can tell your coworker to run the following commands (he needs atlas account too):")
    print("")
    print("vagrant login")
    for (hostid, cmd, process) in shared_process:
      print(cmd + "   # " + hostid)
    print("")
    # wait for ctrl-c and propagate it to stop sharing
    print("Press ctrl-c to stop sharing")
    signal.pause()
    print("Unsharing")
    for (hostid, cmd, process) in shared_process:
      process.sendintr()
      process.wait()

  def update_rudder(self, version):
    """ Update rudder version on all hosts """
    for host in self.hosts.values():
      print(host.run("/usr/local/bin/rudder-setup upgrade-" + host.info['rudder-setup'] + " " + version))

  def status(self):
    """ Show platform status """
    for host_type in host_types.values():
      host_list = []
      for hostname, host in self.hosts.items():
        if isinstance(host, host_type):
          host_list.append(hostname)
      host_type.status(self.name, host_list)

  def api_connection_info(self):
    """ Get informations to connect to the server via the api """
    rudder_url = None
    token = None
    for hostname, host in self.hosts.items():
      if host.info['rudder-setup'] == "server":
        rudder_url = host.get_url()
        token = host.run('cat /root/rudder-token')
    if rudder_url is None or token is None:
      rudder_url = ''
      token = ''
    #  print("This platform has no rudder server, can't run this command")
    #  exit(2)
    return (rudder_url, token)

  def run_scenario(self, name, frmt, run_finally, err_stop, run_only, client_path, params, startTestNumber, destroyOnError=False):
    """ Run a scenario on this platform """
    try:
      # test ruby binary
      (code, rubyver) = shell("ruby --version")
      if re.match(r'jruby', rubyver):
        if not re.match(r'jruby 1.7', rubyver):
          print("WARNING: this is not JRuby 1.7, compatibility unknown")

      elif not re.match(r'ruby 2', rubyver):
        print("ERROR: MRI Ruby needs to be version 2")
        exit(3)

      # Test rspec command
      rspec = "ruby -S rspec --order defined --fail-fast --format " + frmt
      shell(rspec)

      # Get api command line
      (rudder_url, token) = self.api_connection_info()
      rcli = "rudder-cli --skip-verify --url=" + rudder_url + " --token=" + token

      # load and run
      parameters = {}
      for param in params:
        kv = param.split('=')
        parameters[kv[0]] = kv[1]
      scenario.lib.scenario = scenario.lib.Scenario(self, rspec, rcli, frmt, run_only, run_finally, err_stop, parameters, startTestNumber)
      setenv(client_path, rudder_url, token)
      importlib.import_module("scenario." + name)
      if scenario.lib.scenario.errors:
        print("Test scenario '"+ name +"' failed on platform '" + self.name + "'")
        exit(5)
    finally:
      if destroyOnError:
        self.teardown()

  def print_environment(self, client_path):
    """ Print environment used to run tests on this platform """
    (rudder_url, token) = self.api_connection_info()
    setenv(client_path, rudder_url, token)
    print("export PATH=" + os.environ['PATH'])
    print("export PYTHONPATH=" + os.environ['PYTHONPATH'])
    print("export RUDDER_SERVER=" + os.environ['RUDDER_SERVER'])
    print("export RUDDER_TOKEN=" + os.environ['RUDDER_TOKEN'])
    print("alias rcli='rudder-cli --skip-verify --url=" + rudder_url + " --token=" + token + "'")

  def export_test(self, rule_uuid, test_name, scenario=False):
    """ Export a given rule, for use in a test or a scenario """
    # Retrieve data
    (rudder_url, token) = self.api_connection_info()
    endpoint = RudderEndPoint(rudder_url, token, verify=False)
    rule = endpoint.rule_details(rule_uuid)['rules'][0]
    directives = []
    for directive_uuid in rule['directives']:
      directive = endpoint.directive_details(directive_uuid)['directives'][0]
      del directive['id']
      directives.append(directive)

    # create test files
    rule_file = "spec/tests/"+test_name+"_rule.rb"
    test_file = "spec/tests/"+test_name+"_test.rb"
    scenario_file = "scenario/"+test_name+".py"

    make_rule_testfile(rule_file, rule, directives)
    make_user_testfile(test_file)
    print("""
A test file to add the rule via the API has been created in %(rule_file)s
This file is where you can make change to the generated rule or directive, but it works as is.

A generic test file to test if the rule has been properly applied has been created in %(test_file)s
It contains demo code, but since we don't know what the rule does it doesn't contain code.
-> Pleas edit %(rule_file)s !

Add the test to an existing scenario:
- Add the following line before the call to wait_for_generation on all agents
    run('localhost', '%(test_name)s_rule', Err.BREAK, NAME="Test %(test_name)s", GROUP="special:all")
- Add the following line after the call to wait_for_generation
    run_on("agent", ''%(test_name)s_test', Err.CONTINUE)
- Add the following lines before the removal of the agent nodes
    run('localhost', 'directive_delete', Err.FINALLY, DELETE="%(directive_name)s", GROUP="special:all")
    run('localhost', 'rule_delete', Err.FINALLY, DELETE="%(rule_name)s", GROUP="special:all")
""" % {'rule_file': rule_file, 'test_file': test_file, 'test_name': test_name,
       'directive_name': directive['displayName'], 'rule_name': rule['displayName']
      })
    if scenario:
      make_scenario_file(scenario_file, test_name)
      print("Additionnaly, a scenario has been created in " + scenario_file)

  def export_technique_test(self, directive_uuid, test_name, path):
    """ Export a technique test data, for use in a technique test, in the given path """

    # Test destination directory
    if not os.path.isdir(path):
      print("The " + path + " path does not exist.")
      exit(1)

    # Retrieve data
    (rudder_url, token) = self.api_connection_info()
    endpoint = RudderEndPoint(rudder_url, token, verify=False)

    file_check = test_name + ".rb"
    file_metadata = test_name + ".metadata"
    file_directive = test_name + ".json"

    # Generate metadata
    metadata = {}
    metadata["inits"] = []
    metadata["checks"] = [file_check]
    metadata["directives"] = [file_directive]
    metadata["sharedFiles"] = []
    metadata["compliance"] = 100

    make_jsonfile(os.path.join(path, file_metadata), metadata)

    # Generate check file
    make_user_testfile(os.path.join(path, file_check))

    # Generate directive
    directive = endpoint.directive_details(directive_uuid)['directives'][0]

    # This is needed because of #8687, the API does not know these parameters at creation
    if "isEnabled" in directive:
      del directive["isEnabled"]
    if "isSystem" in directive:
      del directive["isSystem"]
    if "priority" in directive:
      del directive["priority"]
    if "tags" in directive:
      del directive["tags"]
    if "policyMode" in directive:
      del directive["policyMode"]
    if "system" in directive:
      del directive["system"]
    if "id" in directive:
      del directive["id"]


    make_jsonfile(os.path.join(path, file_directive), directive)

    print("""
The test content has been generated in %s, it contains:

- %s which contains the metatdata, automatically filled. You can edit the expected compliance (default is 100)
- %s which contains the directive parameters, automatically filled.
- %s which is a stub check file. You need to edit it to describe the expected state
  -> Please edit it!
""" % (path, file_metadata, file_directive, file_check))


###################
# Utility methods #
###################

def empty_handler(signum, frame):
  pass

def setenv(client_path, url, token):
  """ Set environment variables for command calls """
  if client_path is not None:
    os.environ['PATH'] += ":" + client_path + "/cli"
    os.environ['PYTHONPATH'] = client_path +  "/lib.python"
  os.environ['RUDDER_SERVER'] = url
  os.environ['RUDDER_TOKEN'] = token

def load_json(filename):
  """ Load a commented json """
  # read json from file
  file = open(filename, 'r')
  data = file.read()
  file.close()
  data = re.sub("\\/\\/.*", "", data)
  try:
    return json.loads(data)
  except Exception as e:
    print("JSON syntax error in " + filename)
    print(e.message)
    exit(3)

_platform = None
def get_platform(name, override={}):
  """ Get a platform object given its name """
  global _platform
  if _platform is not None:
    return _platform

  platform_description = load_json("platforms/" + name + ".json")
  _platform = Platform(name, platform_description, override)
  return _platform

def list_platforms():
  """ List available platforms """
  for file in os.listdir("platforms"):
    print(file.replace(".json", ""))

def list_scenarii():
  """ List available scenarios """
  for f in os.listdir("scenario"):
    if not f.endswith(".py"):
      continue
    file = f.replace(".py", "")
    if file != "__init__" and file != "lib":
      print(file)

def make_jsonfile(filename, content):
  with open(filename, "w") as fd:
    fd.write('[')
    fd.write(json.dumps(content, sort_keys=True, indent=2, separators=(',', ': ')))
    fd.write(']')

def scenario_doc(name):
  try:
    importlib.import_module("scenario." + name)
  except ValueError as e:
    print(e)

def make_rule_testfile(filename, rule, directives):
  with open(filename, "w") as fd:
    data = """# File generated using rtf test from-rule
# This test creates a rule named '%(displayName)s' and its directive(s)
# And is checks that the api returned correctly

require 'spec_helper'

group = $params['GROUP']

directiveFile = "/tmp/directive.json"
ruleFile = "/tmp/rule.json"

describe "Add a test directive and a rule"  do
      """ % {'displayName': rule['displayName']}
    for idx, directive in enumerate(directives):
      data += """
  # Add directive
  describe command($rudderCli + " directive create --json=" + directiveFile + " %(technique)s %(name)s") do
    before(:all) {
      File.open(directiveFile, 'w') { |file|
        file << <<EOF
%(directive)s
EOF
      }
    }
    after(:all) {
      File.delete(directiveFile)
    }
    its(:exit_status) { should eq 0 }
    its(:stdout) { should match /^"[0-9a-f\\-]+"$/ }
    it {
      # register output uuid for next command
      $uuid%(id)i = subject.stdout.gsub(/^"|"$/, "").chomp()
    }
  end

""" % {'technique': directive['techniqueName'], 'name': directive['displayName'], 'directive': json.dumps(directive, indent=2), 'id': idx}
    data += """
  # create a rule
  describe command($rudderCli + " rule create --json=" + ruleFile + " testRule") do
    before(:all) {
      File.open(ruleFile, 'w') { |file|
        file << <<EOF
{
  "directives": [
"""
    data += ",".join(['"#{$uuid' + str(i) + '}"' for i in range(0, len(directives))])
    data += """
  ],
  "displayName": "%(displayName)s Rule",
  "longDescription": "%(longDescription)s ",
  "shortDescription": "%(shortDescription)s",
  "targets": [
    {
      "exclude": {
        "or": []
      },
      "include": {
        "or": [
          "#{group}"
        ]
      }
    }
  ]
}
EOF
      }
    }
    after(:all) {
      File.delete(ruleFile)
    }
    its(:exit_status) { should eq 0 }
    its(:stdout) { should match /^"[0-9a-f\\-]+"$/ }
    it {
      # register output uuid for next command
      $uuid = subject.stdout.gsub(/^"|"$/, "").chomp()
    }
  end

end
""" % {'displayName': rule['displayName'], 'longDescription': rule['longDescription'], 'shortDescription': rule['shortDescription']}
    fd.write(data)

def make_user_testfile(filename):
  with open(filename, "w") as fd:
    fd.write("""# Sample file generated using rtf test from-rule
# This is where you test your rule

require 'spec_helper'

# Please add your test here
# see http://serverspec.org/resource_types.html for a full documentation of available tests

## Ex: Test that a a package has been installed
#describe package'apache2') do
#  it { should be_installed }
#  it { should be_installed.with_version('2.4.10') }
#end

## Ex: Test that a user exist
#describe user('testuser') do
#  it { should exist }
#  it { should have_home_directory '/home/testuser' }
#end

## Ex: Test that a file exists
#describe file('/etc/passwd') do
#  it { should be_file }
#  it { should be_mode 640 }
#  it { should be_owned_by 'root' }
#  its(:content) { should match /regex to match/ }
#end

## Ex: Test the output of a command
#describe command('ls -al /') do
#  its(:stdout) { should match /bin/ }
#  its(:stderr) { should match /No such file or directory/ }
#  its(:exit_status) { should eq 0 }
#end
""")

def make_scenario_file(filename, test_name):
  with open(filename, "w") as fd:
    fd.write("""# File generated using rtf test from-rule
from scenario.lib import *

# test begins, register start time
start()

run_on("all", 'agent', Err.CONTINUE)

# force inventory
run_on("agent", 'run_agent', Err.CONTINUE, PARAMS="inventory")
run_on("server", 'run_agent', Err.CONTINUE, PARAMS="run")

# accept nodes
for host in scenario.nodes("agent"):
  run('localhost', 'agent_accept', Err.BREAK, ACCEPT=host)

# Add a rule
date0 = host_date('wait', Err.CONTINUE, "server")
run('localhost', '%(test_name)s_rule', Err.BREAK, NAME="Test %(test_name)s", GROUP="special:all")
for host in scenario.nodes("agent"):
  wait_for_generation('wait', Err.CONTINUE, "server", date0, host, 20)

# Run agent
run_on("agent", 'run_agent', Err.CONTINUE, PARAMS="update")
run_on("agent", 'run_agent', Err.CONTINUE, PARAMS="run")

# Test rule result
run_on("agent", '%(test_name)s_test', Err.CONTINUE)

# remove rule/directive
run('localhost', 'directive_delete', Err.FINALLY, DELETE="Test %(test_name)s Directive", GROUP="special:all")
run('localhost', 'rule_delete', Err.FINALLY, DELETE="Test %(test_name)s Rule", GROUP="special:all")

# remove agent
for host in scenario.nodes("agent"):
  run('localhost', 'agent_delete', Err.FINALLY, DELETE=host)

# test end, print summary
finish()
""" % {'test_name': test_name})


def find_tests(techniques, filter, last_version):
  params = "-d "
  if last_version:
    params += "-l "
  if filter is not None and filter != "":
    params += "-f '" + filter + "' "
  cmd = os.getcwd() + "/scripts/technique-files " + params + techniques
  (code, technique_dirs) = shell(cmd)
  tests = []
  for technique in technique_dirs.split("\n"):
    if technique == "":
      continue
    test_dir = technique + "/tests"
    if not os.path.isdir(test_dir):
      continue
    for file in os.listdir(test_dir):
      match = re.search(r'^[\w\-_]+\.metadata$', file)
      if match:
        tests.append(test_dir + "/" + file)
  return tests

##########################
# Command line interface #
##########################

if __name__ == "__main__":
  args = docopt.docopt(__doc__)
  script_dir = os.path.dirname(os.path.realpath(__file__))
  os.chdir(script_dir)
  # Hack nedded because there is no api client package yet
  client_path = script_dir + "/rudder-api-client"
  if not os.path.exists(client_path):
    print("Can't find rudder-api-client, if you install rudder-api-client package, you should patch this script")
    print("If you want to use rudder-api-client from a local repository please type this command:")
    print("ln -s ~/<path_to>/rudder-api-client")
    exit(1)

  if args['platform']:
    if args['list']:
      list_platforms()
    else:
      if args['status']:
        platform = get_platform(args['<platform>'])
        platform.status()
      elif args['setup']:
        override = {}
        for kv in args['<key>=<value>']:
          if '=' in kv:
            (key, value) = kv.split('=')
            override[key] = value
          else:
            override['rudder-version'] = kv
        platform = get_platform(args['<platform>'], override)
        platform.setup(client_path)
      elif args['shutdown']:
        platform = get_platform(args['<platform>'])
        platform.shutdown()
      elif args['snapshot']:
        platform = get_platform(args['<platform>'])
        platform.snapshot()
      elif args['rollback']:
        platform = get_platform(args['<platform>'])
        platform.rollback()
      elif args['destroy']:
        platform = get_platform(args['<platform>'])
        platform.teardown()
      elif args['share']:
        platform = get_platform(args['<platform>'])
        platform.share()
      elif args['export']:
        platform = get_platform(args['<platform>'])
        if args['--ova']:
          platform.export_ova()
        else:
          platform.export()
      elif args['update-rudder']:
        platform = get_platform(args['<platform>'])
        platform.update_rudder(args['<version>'])
      elif args['update-os']:
        pass
  elif args['host']:
    pass
  elif args['scenario']:
    if args['list']:
      list_scenarii()
    elif args['doc']:
      scenario_doc(args['<scenario>'])
    elif args['env']:
      platform = get_platform(args['<platform>'])
      platform.print_environment(client_path)
    elif args['run']:
      filter = args['--filter']
      if filter == []:
        filter = None
      platform = get_platform(args['<platform>'])
      platform.run_scenario(args['<scenario>'], args['--format'], not args['--no-finally'], args['--stop'], filter, client_path, args['<KEY>=<VALUE>'], args['--start'], destroyOnError=args['--destroy-on-error'])
    elif args['ncf_tests']:
      platform = get_platform(args['<platform>'], {})
      platform.setup(client_path)
      if (args['--cfengine-version'] == None):
        args['--cfengine-version'] = ''
      platform.run_scenario("ncf_tests", args['--format'], not args['--no-finally'], args['--stop'], filter, client_path, ["tag=" + args['<version>'], "cfengine_version=" + args['--cfengine-version']], args['--start'], destroyOnError=True)
      platform.teardown()
    elif args['technique']:
      platform = get_platform(args['<platform>'])
      techniques = args['<directory>']
      # Find the tests
      tests = find_tests(techniques, args['--technique'], args['--last-version'])
      if not tests:
        print("There is no test in your techniques directory")
        exit(1)
      # push the techniques
      platform.push_techniques(techniques)
      # run the tests (all at once)
      params = ["test=" + ",".join(tests), "root=" + techniques]
      filter = args['--filter']
      if filter == []:
        filter = None
      # add the reset scenario execution before a technique test, except if --start option is precised
      start = args['--start']
      if start == None:
        args['--start'] = 0
        platform.run_scenario('reset', args['--format'], not args['--no-finally'], args['--stop'], filter, client_path, params, int(args['--start']), destroyOnError=args['--destroy-on-error'])
      platform.run_scenario('technique', args['--format'], not args['--no-finally'], args['--stop'], filter, client_path, params, int(args['--start']), destroyOnError=args['--destroy-on-error'])
  elif args['test']:
    if args['from-rule']:
      platform = get_platform(args['<platform>'])
      platform.export_test(args['<uuid>'], args['<test_name>'], args['--create-scenario'])
    elif args['from-directive']:
      platform = get_platform(args['<platform>'])
      platform.export_technique_test(args['<uuid>'], args['<test_name>'], args['<path>'])
